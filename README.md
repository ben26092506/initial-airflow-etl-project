# Airflow ETL Pipeline

Dieses Projekt enth채lt eine einfache ETL-Pipeline mit Apache Airflow:

- Extract: erzeugt eine Beispiel-CSV
- Transform: verarbeitet Daten mit Pandas
- Load: schreibt transformierte Daten zur체ck

## Dateien
- dags/etl_example.py
- dags/hello_dag.py

## Voraussetzungen
- Apache Airflow 3.x
- Python 3.12
- Pandas

## Ausf체hren
Der DAG wird automatisch im Airflow UI angezeigt und kann dort manuell ausgef체hrt werden.

![Task Instances](images/airflow-TaskInstances.png)

![Extract data - Logs](images/airflow-logs_extract_data.png)

![Transform data - Logs](images/airflow-logs_transform_data.png)

![Load data - Logs](images/airflow-logs_load_data.png)